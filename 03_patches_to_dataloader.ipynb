{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbfcea1",
   "metadata": {},
   "source": [
    "#### **From Geospatial Patches to Model-Ready Batches** \n",
    "\n",
    "This notebook shows how the patch locations generated in Notebook 01 can be connected to a standard PyTorch `Dataset` and `DataLoader`, producing batches suitable for training a segmentation model. \n",
    "\n",
    "The example uses: \n",
    "- a USGS DEM subset of the Colorado River corridor (Grand Canyon)\n",
    "- derived slope-class labels, - TorchGeo’s `GridGeoSampler` to define patch extents; and \n",
    "- a minimal custom `Dataset` for extracting aligned `(X, y)` tensors. \n",
    "  \n",
    "The aim is not to train a model, but to illustrate the final step of the data pipeline: \n",
    "\n",
    "> **Raster → (geospatial sampler) → PyTorch Dataset → DataLoader → batches ready for a model.** \n",
    "\n",
    "This pattern is the same for many spatial ML tasks, such as: \n",
    "- DEM-based terrain or susceptibility models \n",
    "- UAV orthomosaics for condition mapping \n",
    "- DSM/DTM segmentation \n",
    "- Rasterised point-cloud derivatives \n",
    "\n",
    "The focus here is on **clean data flow and alignment**, rather than modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and config\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from torchgeo.samplers import GridGeoSampler, Units\n",
    "from torchgeo.datasets import RasterDataset\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths to DEM and slope classes\n",
    "data_dir = Path('data_out')\n",
    "usgs_dem_path = Path(r'DEME_Zone1-Zone15_2021/DEME_Zone3_2021.tif')\n",
    "dem_path = data_dir / f'{os.path.basename(usgs_dem_path)[:-4]}_clip.tif'\n",
    "slope_class_path = data_dir / f'{os.path.basename(usgs_dem_path)[:-4]}_clip_slope_classes.tif'\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32bd2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created GridGeoSampler with 961 patches of size 256x256 px\n"
     ]
    }
   ],
   "source": [
    "# Load DEM metadata\n",
    "with rasterio.open(dem_path) as src:\n",
    "    dem_crs = src.crs\n",
    "    dem_res = src.res\n",
    "    dem_bounds = src.bounds\n",
    "\n",
    "# Create TorchGeo dataset\n",
    "dem_dataset = RasterDataset(paths=str(dem_path), crs=dem_crs, res=dem_res[0])\n",
    "\n",
    "# Create GridGeoSampler (256x256 px, 50% overlap)\n",
    "patch_size_px = 256\n",
    "stride_px = 128\n",
    "patch_size_m = patch_size_px * dem_res[0]\n",
    "stride_m = stride_px * dem_res[0]\n",
    "grid_sampler = GridGeoSampler(dataset=dem_dataset, size=patch_size_m, stride=stride_m, units=Units.CRS)\n",
    "bboxes = list(grid_sampler)\n",
    "\n",
    "print(f\"✓ Created GridGeoSampler with {len(bboxes)} patches of size {patch_size_px}x{patch_size_px} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449e23b",
   "metadata": {},
   "source": [
    "#### 03: Patches to PyTorch DataLoader\n",
    "\n",
    "This section demonstrates how the geospatial patch extents produced by the sampler can be wrapped in a lightweight `Dataset` and iterated through a `DataLoader`. \n",
    "\n",
    "The goal is to show how raster-based patches become model-ready tensors with consistent shapes, types, and label alignment. \n",
    "\n",
    "This is a minimal, practical example of the interface between geospatial preprocessing and deep-learning workflows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfec918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal PyTorch Dataset for DEM + slope-class patches\n",
    "# Renamed to RasterPatchDataset for generality\n",
    "class RasterPatchDataset(Dataset):\n",
    "    def __init__(self, dem_path, class_path, bboxes):\n",
    "        self.dem_path = dem_path\n",
    "        self.class_path = class_path\n",
    "        self.bboxes = bboxes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bboxes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        bbox = self.bboxes[idx]\n",
    "        with rasterio.open(self.dem_path) as dem_src:\n",
    "            dem_window = from_bounds(bbox.minx, bbox.miny, bbox.maxx, bbox.maxy, dem_src.transform)\n",
    "            dem_patch = dem_src.read(1, window=dem_window).astype(np.float32)\n",
    "        with rasterio.open(self.class_path) as class_src:\n",
    "            class_window = from_bounds(bbox.minx, bbox.miny, bbox.maxx, bbox.maxy, class_src.transform)\n",
    "            class_patch = class_src.read(1, window=class_window).astype(np.int64)\n",
    "        # Normalize DEM (min-max to [0,1]), excluding zeros (often used as nodata)\n",
    "        dem_valid = dem_patch[dem_patch != 0]\n",
    "        if dem_valid.size > 0:\n",
    "            dem_min, dem_max = dem_valid.min(), dem_valid.max()\n",
    "            dem_patch = (dem_patch - dem_min) / (dem_max - dem_min + 1e-6)\n",
    "            dem_patch[dem_patch < 0] = 0\n",
    "            dem_patch[dem_patch > 1] = 1\n",
    "        # Convert to torch tensors\n",
    "        X = torch.from_numpy(dem_patch).unsqueeze(0)  # (1, H, W)\n",
    "        y = torch.from_numpy(class_patch)  # (H, W)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc2be59",
   "metadata": {},
   "source": [
    "#### DataLoader: batching and inspecting model-ready patches\n",
    "\n",
    "This cell wraps the patch dataset in a PyTorch `DataLoader`, which handles batching and shuffling. We then fetch a single batch and print the shapes, dtypes, and value ranges for both the input (DEM) and target (slope class) tensors. This confirms that the data is correctly formatted and ready to be passed to a segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd9a2b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([4, 1, 256, 256])\n",
      "y shape: torch.Size([4, 256, 256])\n",
      "X dtype: torch.float32\n",
      "y dtype: torch.int64\n",
      "X min/max: 0.0 1.0\n",
      "y min/max: 0 4\n"
     ]
    }
   ],
   "source": [
    "# DataLoader wiring\n",
    "dataset = RasterPatchDataset(dem_path, slope_class_path, bboxes)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Iterate one batch\n",
    "batch = next(iter(loader))\n",
    "X, y = batch\n",
    "print('X shape:', X.shape)  # (batch, 1, H, W)\n",
    "print('y shape:', y.shape)  # (batch, H, W)\n",
    "print('X dtype:', X.dtype)\n",
    "print('y dtype:', y.dtype)\n",
    "print('X min/max:', X.min().item(), X.max().item())\n",
    "print('y min/max:', y.min().item(), y.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f12aed",
   "metadata": {},
   "source": [
    "#### Dummy model forward pass: verifying plug-and-play compatibility\n",
    "\n",
    "This cell defines a minimal convolutional neural network (two Conv2d layers with ReLU activation) and runs a batch of patches through it. This demonstrates that the data produced by the DataLoader is already in the correct shape and type for direct use in a segmentation model, such as a U-Net. The output shape and dtype are printed to confirm compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d5ee758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([4, 1, 256, 256])\n",
      "Model output dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Optional: Dummy model forward pass\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 8, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(8, 1, kernel_size=3, padding=1)\n",
    ")\n",
    "\n",
    "out = model(X)  # (batch, 1, H, W)\n",
    "print('Model output shape:', out.shape)\n",
    "print('Model output dtype:', out.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49513bc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Summary**\n",
    "\n",
    "This notebook shows how the geospatial patch sampling layer from Notebook 01 connects to a standard PyTorch batching workflow. \n",
    "\n",
    "- The `Dataset` reads DEM and slope-class tiles on demand, normalises the input, and returns aligned `(X, y)` tensors. \n",
    "- A `DataLoader` then provides batches with consistent shapes that can be passed directly to a segmentation model. \n",
    "- Although no training loop is included here, this structure is equivalent to what would be used for a U-Net or similar architecture. \n",
    "\n",
    "Key points: \n",
    "1. The sampler defines patch locations in geographic space; the `Dataset` resolves these to pixel windows. \n",
    "2. Each batch contains consistently shaped tensors (`X: [B, 1, H, W]`, `y: [B, H, W]`). \n",
    "3. The example keeps the implementation minimal, focusing on clarity of data flow rather than modelling details. \n",
    "4. The same pattern applies to DEMs, UAV imagery, DSM/DTMs, or rasterised point-cloud products. \n",
    "\n",
    "Together with Notebook 01, this notebook provides a clear template for building geospatial deep-learning data pipelines using TorchGeo and PyTorch. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgeo_python10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
